{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5791652d",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Capstone: Pixel Pilot, Object Detection for Self Driving Car\n",
    "# Annex Video Editing Code Snippet\n",
    "\n",
    "> Authors: Michael King Sutanto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f5391",
   "metadata": {},
   "source": [
    "This Jupyter Notebook serves as an annex containing code snippets related to videos editing.  \n",
    "It contains a collection of Python code snippets that demonstrate various functionalities such as cutting, combining, converting to images, and video inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb316e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac8a677",
   "metadata": {},
   "source": [
    "### Cut Video\n",
    "Cut video based on given start and end time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2afbe880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def cut_video(input_path, output_path, start_time, end_time, fps):\n",
    "    # Load the video file\n",
    "    video = VideoFileClip(input_path)\n",
    "    \n",
    "    # Check if video.fps is None and set fps explicitly if needed\n",
    "    fps = float(fps) if fps is not None else 24.0  # Ensure fps is a float\n",
    "    print(\"Using FPS:\", fps)\n",
    "    \n",
    "    # Cut the clip\n",
    "    clip = video.subclip(start_time, end_time)\n",
    "    \n",
    "    # Write the result to the output file\n",
    "    clip.write_videofile(output_path, fps=fps, codec='libx264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ad66fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FPS: 29.97\n",
      "Moviepy - Building video ../datasets/videos/test_short5.mp4.\n",
      "MoviePy - Writing audio in test_short5TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ../datasets/videos/test_short5.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../datasets/videos/test_short5.mp4\n"
     ]
    }
   ],
   "source": [
    "# Define your video paths and cut times\n",
    "input_video_path = '../datasets/videos/test.mp4'\n",
    "output_video_path = '../datasets/videos/test_short5.mp4'\n",
    "start_time = (7 * 60) + 45 # converting time to seconds\n",
    "end_time = (8 * 60) + 10\n",
    "fps = 29.97  # Manually set this; ensure it's a float\n",
    "\n",
    "cut_video(input_video_path, output_video_path, start_time, end_time, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c43268fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FPS: 60.0\n",
      "Moviepy - Building video ../datasets/videos/test_short1.mp4.\n",
      "Moviepy - Writing video ../datasets/videos/test_short1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../datasets/videos/test_short1.mp4\n"
     ]
    }
   ],
   "source": [
    "# Define your video paths and cut times\n",
    "input_video_path = '../datasets/videos/test.mp4'\n",
    "output_video_path = '../datasets/videos/test_short1.mp4'\n",
    "start_time = (3 * 60) + 28  # converting time to seconds\n",
    "end_time = (4 * 60)\n",
    "fps = 60  # Manually set this; ensure it's a float\n",
    "\n",
    "cut_video(input_video_path, output_video_path, start_time, end_time, fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12861fd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb4d3e",
   "metadata": {},
   "source": [
    "### Convert Video to Images Every 15 Frames\n",
    "Extract images from a video with a selected frame interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13437610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 11257 images.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load the video\n",
    "video_path = '../datasets/videos/train.mp4'\n",
    "output_folder = '../datasets/images/'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_rate = 15  # the interval to save frames\n",
    "\n",
    "frame_count = 0\n",
    "saved_frame_count = 0\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break  # no more frames, or can't read video\n",
    "\n",
    "    # Save frame every 15 frames\n",
    "    if frame_count % frame_rate == 0:\n",
    "        output_path = os.path.join(output_folder, f\"frame_{saved_frame_count}.jpg\")\n",
    "        cv2.imwrite(output_path, frame)\n",
    "        saved_frame_count += 1\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "print(f\"Extracted {saved_frame_count} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaba3a5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512b898d",
   "metadata": {},
   "source": [
    "### Make Folder 1 Match Folder 2\n",
    "Use case:  \n",
    "For example initially we used 720p video and we already filtered out unused images. And we want to update the images to 1080p.  \n",
    "We can use this code to delete unused images in the new 1080p folder to match the 720p folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a189089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the paths to your folders\n",
    "folder1_path = r'C:\\Users\\MichaelKS\\GA\\capstone\\datasets\\images'\n",
    "folder2_path = r'C:\\Users\\MichaelKS\\GA\\capstone\\datasets\\images_720'\n",
    "\n",
    "# List all files in both folders\n",
    "files_in_folder1 = set(os.listdir(folder1_path))\n",
    "files_in_folder2 = set(os.listdir(folder2_path))\n",
    "\n",
    "# Determine which files are in Folder 1 but not in Folder 2\n",
    "files_to_delete = files_in_folder1 - files_in_folder2\n",
    "\n",
    "# Delete these files from Folder 1\n",
    "for file_name in files_to_delete:\n",
    "    file_path = os.path.join(folder1_path, file_name)\n",
    "    os.remove(file_path)\n",
    "    print(f\"Deleted {file_path}\")\n",
    "\n",
    "print(\"Folder 1 has been updated to match Folder 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea9f7d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f038d",
   "metadata": {},
   "source": [
    "### Video Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "581ac0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Load model\n",
    "model = YOLO('../model/runs/detect/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618d729",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "results = model(source='../datasets/videos/test_0.mp4', show=True, conf=0.3, save=True)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac01ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc54818e",
   "metadata": {},
   "source": [
    "### Video Inference With Frame Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f53aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def get_name(file_path):\n",
    "  name_idx = 0\n",
    "  file_pos = (file_path).rfind('\\\\')\n",
    "\n",
    "  if(file_pos == -1):\n",
    "      file_pos = (file_path).rfind('/')\n",
    "\n",
    "      if(file_pos == -1):\n",
    "          file_pos = 0\n",
    "\n",
    "  name_idx = file_pos + 1\n",
    "\n",
    "  name = file_path[name_idx:]\n",
    "\n",
    "  return name\n",
    "\n",
    "def get_save_path(file_name, folder_name):\n",
    "  path = \"result\"\n",
    "  save_path = os.path.join(path, folder_name)\n",
    "\n",
    "  exists = os.path.exists(save_path)\n",
    "\n",
    "  if(not exists):\n",
    "      os.makedirs(save_path)\n",
    "\n",
    "  save_path = os.path.join(save_path, file_name)\n",
    "\n",
    "  return save_path\n",
    "\n",
    "def draw_box(img, detection_results, class_list, colors, label_size) :\n",
    "  # Get information from result\n",
    "  xyxy = detection_results.boxes.xyxy.numpy()\n",
    "  confidence = detection_results.boxes.conf.numpy()\n",
    "  class_ids = detection_results.boxes.cls.numpy().astype(int)\n",
    "  # Pack together for easy use\n",
    "  results = list(zip(class_ids, confidence, xyxy))\n",
    "  # Copy image, in case that we need original image for something\n",
    "  out_image = img.copy()\n",
    "\n",
    "  for result in results :\n",
    "    # Unpack\n",
    "    class_id, con, box = result\n",
    "    # Choose color\n",
    "    box_color = colors[int(class_id)]\n",
    "    text_color = (255,255,255)\n",
    "    # Get Class Name\n",
    "    label = class_list[int(class_id)]\n",
    "    # Draw object box\n",
    "    first_half_box = (int(box[0]),int(box[1]))\n",
    "    second_half_box = (int(box[2]),int(box[3]))\n",
    "    cv2.rectangle(out_image, first_half_box, second_half_box, box_color, 2)\n",
    "\n",
    "    # Create text\n",
    "    text_print = '{label} {con:.2f}'.format(label = label, con = con)\n",
    "    # Locate text position\n",
    "    text_location = (int(box[0]), int(box[1] - 10 ))\n",
    "    # Get size and baseline\n",
    "    labelSize, baseLine = cv2.getTextSize(text_print, cv2.FONT_HERSHEY_SIMPLEX, label_size, 1)\n",
    "\n",
    "    # Draw text's background\n",
    "    cv2.rectangle(out_image\n",
    "                    , (int(box[0]), int(box[1] - labelSize[1] - 10 ))\n",
    "                    , (int(box[0])+labelSize[0], int(box[1] + baseLine-10))\n",
    "                    , box_color , cv2.FILLED)\n",
    "    # Put text\n",
    "    cv2.putText(out_image, text_print ,text_location\n",
    "                , cv2.FONT_HERSHEY_SIMPLEX , label_size\n",
    "                , text_color, 2, cv2.LINE_AA)\n",
    "\n",
    "  return out_image\n",
    "\n",
    "def draw_fps(avg_fps, img):\n",
    "  avg_fps_str = float(\"{:.2f}\".format(avg_fps))\n",
    "\n",
    "  cv2.rectangle(img, (10,2), (280,50), (255,255,255), -1)\n",
    "  cv2.putText(img, \"FPS: \"+str(avg_fps_str), (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), thickness=3)\n",
    "\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ad2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(source, model, folder_name, img_size, label_size=1):\n",
    "  # Initialize video\n",
    "  cap = cv2.VideoCapture(source)\n",
    "\n",
    "  # Initialize YOLOv8 model\n",
    "  model_path = model\n",
    "  yolov8_detector = YOLO(model_path)\n",
    "\n",
    "  # Class Name and Colors\n",
    "  label_map = yolov8_detector.names\n",
    "  colors = [[random.randint(0, 255) for _ in range(3)] for _ in label_map]\n",
    "\n",
    "  # FPS Detection\n",
    "  frame_count = 0\n",
    "  total_fps = 0\n",
    "  avg_fps = 0\n",
    "\n",
    "  # FPS Video\n",
    "  total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "  frame_width = int(cap.get(3))\n",
    "  frame_height = int(cap.get(4))\n",
    "\n",
    "  video_frames = []\n",
    "\n",
    "  while cap.isOpened():\n",
    "    # Press key q to stop\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        # Read frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    # # Start Time\n",
    "    start = time.time()\n",
    "    # Update object localizer\n",
    "    results = yolov8_detector.predict(frame, imgsz=img_size, verbose=False)\n",
    "    result = results[0].cpu()\n",
    "\n",
    "    # Draw Detection Results\n",
    "    combined_img = draw_box(frame, result, label_map, colors, label_size)\n",
    "\n",
    "    end = time.time()\n",
    "    # # End Time\n",
    "\n",
    "    # Draw FPS\n",
    "    frame_count += 1\n",
    "    fps = 1 / (end - start)\n",
    "    total_fps = total_fps + fps\n",
    "    avg_fps = total_fps / frame_count\n",
    "\n",
    "    combined_img = draw_fps(avg_fps, combined_img)\n",
    "\n",
    "    # Append frame to array\n",
    "    video_frames.append(combined_img)\n",
    "\n",
    "    #\n",
    "    print(\"(%2d / %2d) Frames Processed\" % (frame_count, total_frames))\n",
    "\n",
    "  print(\"\\nCreate a Video:\")\n",
    "\n",
    "  # Get a file name\n",
    "  file_name = get_name(source)\n",
    "  # Get Save Path\n",
    "  save_path = get_save_path(file_name, folder_name)\n",
    "  # Create VideoWriter object.\n",
    "  out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'XVID'), int(avg_fps), (frame_width, frame_height))\n",
    "\n",
    "  for frame in video_frames:\n",
    "    out.write(frame)\n",
    "\n",
    "  out.release()\n",
    "\n",
    "  print(\"Video is saved in: \"+save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e9e22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict with FPS\n",
    "detection('../datasets/videos/cam4_720_short.mp4', '../model/runs/detect/train/weights/best.pt', \"predict\", 736)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b074654a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab8b3e6",
   "metadata": {},
   "source": [
    "## Combine videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c366366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../datasets/videos/predict/pred_test_combined.avi.\n",
      "Moviepy - Writing video ../datasets/videos/predict/pred_test_combined.avi\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../datasets/videos/predict/pred_test_combined.avi\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "\n",
    "# List of video file names\n",
    "video_files = [f'../datasets/videos/predict/pred_test_{i}.avi' for i in range(0,5)]\n",
    "\n",
    "# List to store VideoFileClip objects\n",
    "clips = []\n",
    "\n",
    "# Load each video file and store as VideoFileClip object\n",
    "for file in video_files:\n",
    "    clip = VideoFileClip(file)\n",
    "    clips.append(clip)\n",
    "\n",
    "# Concatenate the clips\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "# Write the final clip to a new file\n",
    "final_clip.write_videofile('../datasets/videos/predict/pred_test_combined.avi', codec='libx264', bitrate='5000k', threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3cfa75b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../datasets/videos/predict/pred_test_combined.mp4.\n",
      "Moviepy - Writing video ../datasets/videos/predict/pred_test_combined.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../datasets/videos/predict/pred_test_combined.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "\n",
    "# List of video file names\n",
    "video_files = [f'../datasets/videos/predict/pred_test_{i}.avi' for i in range(1,4)]\n",
    "\n",
    "# List to store VideoFileClip objects\n",
    "clips = []\n",
    "\n",
    "# Load each video file and store as VideoFileClip object\n",
    "for file in video_files:\n",
    "    clip = VideoFileClip(file)\n",
    "    clips.append(clip)\n",
    "\n",
    "# Concatenate the clips\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "# Write the final clip to a new file\n",
    "final_clip.write_videofile('../datasets/videos/predict/pred_test_combined.mp4', codec='libx264', bitrate='5000k', threads=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
